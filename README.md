We explored the low interpretability of how "black box" ML methods produce their output hinders their clinical adoption. 
We applied the CNN model for Breast Cancer Holographic Dataset, and we used LIME, SHAP, LRP, Deep Taylor Explainable AI methods to interpret the model's predictions.
They helped us in identifying "turning points" where features go from favoring survived to favoring deceased (or vice versa)
